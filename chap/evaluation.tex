\subsection{Performance Evaluation}
\label{sec:eva}
%\subsection{The distribution of AES execution time}
%The Figure~\ref{aesdistri} shows the distribution of AES execution time of the original AES and the AES using our defense scheme. The original AES execution time is distributed all positions on x axis means the execution time is affected by the different input plaintexts. However, the execution time of AES with our defense scheme is distributed at position that is less than the computation threshold ,the T_{mm} and the position larger than T_{mm}. Therefore, the relation between the AES execution time and the different input plaintexts is eliminated. So our defense scheme is efficient against the cache timing attacks.
%
%\begin{figure}
%  \centering
%  \includegraphics[width=0.7\textwidth]{pic/aesdistruction.pdf}\\
%  \caption{the distribution of AES execution time of the original AES and the AES using our defense scheme.}\label{aesdistri}
%\end{figure}

%\textbf{Eliminating remote cache timing side channels.}

This section shows that,
with the {\scshape{Warm+Delay}} scheme, the distribution of AES execution time are separated into two parts: less than $T_{nm}$ and greater than $T_{mm}$,
   which meets our expectation.
Then, we evaluate the performance in different aspects.
We compare it with different {\vwarm} strategies to show that the integration scheme has the best performance among the different strategies integrating {\vwarm} and {\vdelay}.
We measure the performance of several different timing side-channel defenses.
        It is shown that {\scshape{Warm+Delay}} produces better performance than other software-based methods,
        either running as an encryption service or integrated in an Apache HTTPS server.
%The overhead of our scheme is acceptable in the practical environment.


%Our scheme aims to make the observed AES execution time independent of the input.
\noindent\textbf{The distribution of the encryption execution time with {\scshape{Warm+Delay}}.}
%To show the security of {\scshape{Warm+Delay}} scheme,
We measure the AES execution time implemented with the {\scshape{Warm+Delay}} scheme,
    and compare it with the unprotected version, for  $2^{30}$ random plaintexts.

Fig. \ref{pic:sec} shows the distributions of the AES execution time for two implementations,
    which will be observed by attackers.
With {\scshape{Warm+Delay}},
    almost all results are in the range of (0, $T_{nm} + 2T_{GetTime}$] and [$T_{mm}+2T_{GetTime}$, +$\infty$),
        where $T_{GetTime}$ is the cost of \verb+RDTSCP+, because {\scshape{GetTime}} is called at least twice (Lines 2 and 4 in Algorithm \ref{alg:aesdefense}).
%    between $T_{nm}$ and $T_{mm}$ are delayed to the value greater than $T_{mm}$.
%The result of {\scshape{Warm+Delay}} is greater than the unprotected version because of the cost of {\scshape{GetTime}}
%The distribution between $T_{nm}$ and $T_{mm}$ is exploitable,
%    which is delayed to $T_{mm}$ in the {\scshape{Warm+Delay}} scheme.
A small set appears around the position of 1750 cycles due to task scheduling, which are unexploitable constant results.
In this case, the average execution time of {\scshape{Warm+Delay}}  is less than $1.29$ times of the unprotected implementation.

\begin{figure}[t]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.5\textwidth]{pic/ori_scheme_distri.pdf}\\
  \caption{The distribution of the observed AES execution time with different plaintexts.}\label{pic:sec}
\end{figure}


\noindent\textbf{Performance of different {\vwarm} strategies.}
We compare conditional {\vwarm} with other strategies that are configured with different $P_{1}$ and $P_{2}$:
    perform {\vwarm} with $P_{1}\in[0,1]$  when a cache miss occurs during the previous encryption,
     and with $P_{2}\in[0,1]$ in other states.
They are compared  in different scenarios: low workload, high CPU workload and high memory workload.

With low workload, no other task except the evaluated AES implementation runs.
We use the SysBench benchmark to simulate the CPU and memory workloads. % in parallel with the AES encryption.
We run SysBench in its CPU mode, which  launches $16$ threads to issue 10K requests to search the primes up to 300K,
 to produce the CPU workload.
For the memory workload, we adopt SysBench with $16$ threads in its memory mode, which reads or writes 1KB blocks each time to access total 3GB data on one CPU core.
The evaluated AES implementation and the concurrent workload run on the same CPU core.
The interval of task OS scheduling is set as $1$ ms and $4$ ms, respectively.
In each case, we perform AES encryption with  $2^{30}$ random plaintexts.


%% The main overhead is caused by the timer function.
Fig. \ref{pic:eval} shows that,
in any case, conditional {\scshape{Warm}} is the best,
    and the strategy with $P_1=0.5$ and $P_2=1$ is the worst.
%Moreover, we approximately calculated $P_{e}$ under different workloads.
% When the {\scshape{Eviction}} event occurs, the encryption time will be greater than $T_{nm}$;
%but not all encryption time greater than $T_{nm}$ is caused by {\scshape{Eviction}}.
%   Based on the analysis in Section~\ref{remark}, there are other cases that result in the encryption time greater than $T_{nm}$.
%Fortunately, these cases occur very little.
%  So, we use the number of AES encryption whose execution time is greater than $T_{nm}$ to approximate $P_{e}$,
%   of which the value is a little greater than $P_{e}$.
%The approximate value of is in Table~\ref{tbl:pevict}.
%%which proves the best performance of our {\scshape{Warm+Delay}} scheme according to the Theorem 4.

%\begin{table}[b]
%  \centering
%  \small
%  \caption{The value of $P_{e}$ under different workload.}
%  \label{tbl:pevict}
%   \begin{tabular}{|m{0.84in}|m{0.6in}|m{0.6in}|m{0.71in}|}
%   \hline
%   {Interval of task scheduling}& Low workload  & High CPU workload & High memory workload   \\
%   \hline
%   {1 ms} & $1.87\times10^{-4}$ & $1.99\times10^{-4}$ & $2.20\times10^{-3}$ \\
%   \hline
%   {4 ms} & $4.67\times10^{-5}$ & $7.52\times10^{-5}$ & $7.88\times10^{-5}$  \\
%   \hline
%   \end{tabular}
%\end{table}

%0.000186894
%0.000199487
%0.002195746
%
%4.6663E-05
%7.52006E-05
%7.88113E-05

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{pic/performance_warm.pdf}\\
    \caption{AES execution performance of different {\vwarm} strategies.}
    \label{pic:eval} %% label for entire figure
\end{figure}


\noindent\textbf{Comparison with other defenses.}
%\textbf{[[if possible, also in different scenarios as Fig. 6; more comprehensive]]}
{\scshape{Warm+Delay}} is compared with other timing side-channel defenses:
 AES-NI, compact table \cite{openssl} and bit-sliced implementation \cite{bitsliced}.
Each method encrypts random plaintexts for $2^{30}$ times.

Fig. \ref{pic:diffscheme} shows that,
    hardware AES-NI has the best performance,
    and the {\scshape{Warm+Delay}} scheme is the best among all software implementations.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{pic/diff_scheme_comp3.pdf}\\
    \caption{Performance of different defense methods.}
    \label{pic:diffscheme} %% label for entire figure
\end{figure}


\noindent\textbf{Performance when integrated in HTTPS servers.}
We applied each solution to protect the AES implementation in OpenSSL,
    which serves as the cryptographic engine in an Apache HTTPS server.
Apache serves several web pages of different sizes with TLSv1.2.
     The TLS cipher suit is ECDHE-RSA-AES128-SHA256.
      The client runs on another computer in 1Gbps LAN with the server.
       ApacheBench issues 10K requests with various request sizes,
        and we measure the HTTPS server throughput.

The HTTPS throughput is shown in Fig. \ref{fig:apacheperformance}.
 When the unprotected AES is used, the throughput is 27.2 requests per second for 1MB data.
With {\scshape{Warm+Delay}}, the throughput is 23.5 requests per second for 1MB data.
{\scshape{Warm+Delay}} scheme has a little influence on the performance.
    As the requested data increase, the performance influence caused by the {\scshape{Warm+Delay}} scheme increases gradually.
    %随着请求数据增大，变化如何
%    Furthermore, we compare the throughput using different defense methods involved in TLS protocol.
Meanwhile,     in Fig. \ref{fig:apacheperformance}, {\scshape{Warm+Delay}} is
    better than other countermeasures except hardware AES-NI.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.45\textwidth]{pic/openssl_apache3.pdf}\\
  \caption{Performance of different defense methods in Apache HTTPS servers}
  \label{fig:apacheperformance}
\end{figure}s






%无负载，高负载cpu ， 高负载内存读取运算 三种情况下的：
%原始AES计算时间
%不进行warm的AES
%每次进行warm的AES
%概率为1/2,1/3 进行warm的AES
%条件warm（我们的方案） 的AES 的计算时间

%
%\begin{CJK}{UTF8}{gkai}
%原始的AES 和 方案的AES 效率进行比较
%
%\end{CJK}


